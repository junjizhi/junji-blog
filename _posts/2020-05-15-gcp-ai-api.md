---
layout: post
title: "How To Consume GCP AI Model Via API"
categories: [All, Technical]
tags: [GCP, Google Cloud Platform, Google Cloud AI]
fullview: false
excerpt: My notes about how to send prediction requests to Google Cloud Platform AI models
comments: true
---

Google has a series of machine learning products ([AI Platform](https://cloud.google.com/ai-platform), [AutoML](https://cloud.google.com/automl), etc.) and all kinds of documentation. I was lost when reading [GCP docs](https://cloud.google.com/ai-platform/prediction/docs/using-pipelines-for-preprocessing#send_online_prediction_request), so I decided to take notes.

If you are extending an existing system / component to connect to Google Cloud Platform (GCP) AI models, e.g., sending prediction requests,
these notes summarize what you know as a dev.

## Typical Usage Scenario

Your company has a team of data scientists who already knows deploying models to GCP. Now they are asking devs to integrate the models 
into production systems. Your existing system are hosted somewhere, e.g., AWS.

As an example, your data scientists have an awesome model to predict tomorrow's stock price (output). All you need to provide is your name and birthday (input). Then you can build a UI widget on your web page which sends the prediction requests with the input to the AI model and display its response.

## How do you consume GCP AI Platform model?
According to [GCP doc](https://cloud.google.com/ai-platform/prediction/docs/using-pipelines-for-preprocessing#send_online_prediction_request), assuming the data science team has deployed the model to GCP AI platform, they should give you the following info:

```
PROJECT_ID
VERSION_NAME
MODEL_NAME
```

Then, you can call the REST API using an access token in the request header, something like below: 

```bash
curl -X POST -H "Content-Type: application/json" -d @input.json \
-H "Authorization: Bearer `gcloud auth print-access-token`" \
"https://ml.googleapis.com/v1/projects/${PROJECT_ID}/models/${MODEL_NAME}/versions/${VERSION_NAME}:predict"
```

## What does the request data look like?
In above `curl` sample command, you may notice there's a `@input.json` argument. It is a local file that looks like:

```json
{
  "instances": [
    [25, "Private", 226802, "11th", 7, "United-States"],
    [38, "Private", 89814, "HS-grad", 9, "United-States"]
  ]
}
```

According to the [GCP doc](https://cloud.google.com/ai-platform/prediction/docs/using-pipelines-for-preprocessing#format_data_for_prediction), the `input.json` have to have the same dimensions as expected by the model. 

Ask your data scientists for the model input features and they should know.

## How do you authenticate your request?
The model API is probably proprietary and you probably don't want the public to access it.

The answer is: access token.

You can follow the instructions to [generate access tokens](https://cloud.google.com/dataprep/docs/html/Manage-API-Access-Tokens_145281444#generate-new-token). Once you have it, add it to the request header in your
request to the REST API (See above question for an example usage).

